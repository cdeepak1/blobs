{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d925139-1ef3-4f3c-8874-6e5f083cf940",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create core area masks\n",
    "This code creates masks for all events in the DeepExtremes database. An event mask includes all pixels that have been part of the respective event at least during one day. The masks are later used to compute the ecosystem response over event-affected area only. This ensures that no other area than the actual event area affect the calculation of the response parameters. This should be more exact compared to the previous bounding-box approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d64a4da4-1d94-4136-a7a4-a3079a2a96e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from xcube.core.store import new_data_store\n",
    "import os\n",
    "from datetime import date, timedelta\n",
    "import numpy.ma as ma\n",
    "import netCDF4 as nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30280cb9-c90c-49dc-ac17-92c18a8d4bac",
   "metadata": {},
   "source": [
    "We first load the summary table of all DeepExtremes events and create a dataframe of it that fits our purposes. We require the duration of each event to be numeric, we remove events that are shorter than five days as we expect them to have no observable influence on the vegetation parameters we are looking at (because of water and energy stocks in the vegetation) and we convert start and end date to actual datetime objects as we will work with dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28fbb31d-750c-4045-b3f9-4b657d4d2fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 20592 entries shorter than 5 days.\n",
      "Final dataframe has 17052 entries.\n"
     ]
    }
   ],
   "source": [
    "# Load summary table of DeepExtremes events\n",
    "df_summary = pd.read_csv(\"https://s3.bgc-jena.mpg.de:9000/deepextremes/v3/MergedEventStats_landonly.csv\")\n",
    "\n",
    "# Create new column 'duration_days' with numeric values\n",
    "df_summary['duration_days'] = df_summary['duration'].str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "# Drop events shorter than 5 days\n",
    "n_entries = len(df_summary)\n",
    "df_summary = df_summary[df_summary['duration_days'] > 4]\n",
    "\n",
    "# Output\n",
    "print(f\"Removed {n_entries - len(df_summary)} entries shorter than 5 days.\")\n",
    "print(f\"Final dataframe has {len(df_summary)} entries.\")\n",
    "\n",
    "# Convert date columns from strings to actual datetime objects\n",
    "df_summary['start_time'] = pd.to_datetime(df_summary['start_time'])\n",
    "df_summary['end_time'] = pd.to_datetime(df_summary['end_time'])\n",
    "\n",
    "# Set the label as the index  as unique identifier to iterate over\n",
    "df_summary.set_index('label', inplace=True)\n",
    "\n",
    "# Sort dataframe by event label\n",
    "df_summary = df_summary.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d405681-8eb7-4f79-b097-5e68ce4ac945",
   "metadata": {},
   "source": [
    "Next, we load the DeepExtremes labelcube that contains all events that were identified in the project. The values of this datacube correspond to the labels of the events from the summary table. Thus, each event is represented as a number of connected pixels that span over the time and space dimensions of the datacube. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb41830-a9a5-4f96-a6e0-f9ec298d1722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load labelcube\n",
    "ds_blobs = xr.open_zarr('https://s3.bgc-jena.mpg.de:9000/deepextremes/v3/mergedlabels.zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dc3840-d879-4f77-bd33-6917a5561894",
   "metadata": {},
   "source": [
    "We define a dictionary that contains a list of all time stamps for each event in df_summary. These will be used to retrieve the time slices for each event that will be merged to the core area in the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58934642-f266-4eb7-b468-7607e9468003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to create a list of timestamps from given start and end date\n",
    "def generate_date_list(start_date, end_date):\n",
    "  \"\"\"\n",
    "  Generates a list of daily timestamps (date objects) from a start date to an end date of an event.\n",
    "\n",
    "  Args:\n",
    "      start_date (datetime.date): The starting date (inclusive).\n",
    "      end_date (datetime.date): The ending date (inclusive).\n",
    "\n",
    "  Returns:\n",
    "      list: A list of datetime.date objects representing daily timestamps.\n",
    "  \"\"\"\n",
    "  date_list = []\n",
    "  current_date = start_date\n",
    "  while current_date <= end_date:\n",
    "    date_list.append(current_date)\n",
    "    current_date += timedelta(days=1)\n",
    "  return date_list\n",
    "\n",
    "# Initialize an empty dictionary\n",
    "dict_label_dates = {}\n",
    "\n",
    "# Iterate over all events in the dataframe df_summary\n",
    "for index, row in df_summary.iterrows():\n",
    "    start_date = row['start_time'] # Set start date of respective event\n",
    "    end_date = row['end_time'] # Set end date of respective event\n",
    "    dates_list = generate_date_list(start_date, end_date) # Create list of daily time stamps between start and end date\n",
    "    dict_label_dates[index] = dates_list # Write this list to the dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc15f73c-bb0f-4f3d-ae01-adb810e2838f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create relative path\n",
    "current_directory = os.getcwd() # Get the current script's directory\n",
    "\n",
    "data_directory = os.path.join(current_directory, '..', 'data/masks') # Construct the path to the data directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91437a0e-f6b8-42f8-9190-4bdf0b2f09b1",
   "metadata": {},
   "source": [
    "The next step is the actual creation of one core area mask for each event in df_summary. As this process is very time and memory consuming, the results will be written to file directly. Each iteration writes a core area mask as a numpy array using the .npy file format. Each of these files will be named after the corresponding event label which will be helpful later on when using these as masks for the calculation of ecosystem response. \n",
    "\n",
    "We did not find any other suitable host for the data, so the results will be stored in a separate folder in the data directory of this GitLab repository. The mask-folder is included in the .gitignore file and thus is not part of the version control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "275641d0-1d4b-40b0-9249-ed25ddb9c7f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop over each label and its associated event days\n",
    "\n",
    "for label, event_days in dict_label_dates.items():\n",
    "    \n",
    "    # Initialize core_area_mask as a boolean array of the same shape as a single time slice, filled with False\n",
    "    time_slice_shape = ds_blobs.sel(Ti=event_days[0])['labels'].shape\n",
    "    core_area_mask = np.zeros(time_slice_shape, dtype=bool)\n",
    "\n",
    "    # Loop over each date to update the core_area_mask\n",
    "    for event_day in event_days:\n",
    "        time_slice = ds_blobs.sel(Ti=event_day)  # Get one time slice of the event per iteration\n",
    "        event_mask = ma.masked_where(time_slice['labels'] != label, time_slice['labels'])  # Mask time slice where the label exists\n",
    "\n",
    "        # Update core_area_mask: True where label occurs at least once\n",
    "        core_area_mask = np.logical_or(core_area_mask, event_mask == label)\n",
    "\n",
    "    # Convert the final core_area_mask to a general array \n",
    "    core_area_mask = np.asarray(core_area_mask)\n",
    "\n",
    "    # Save the core_area_mask to a file named after the label\n",
    "    filename = os.path.join(data_directory, f\"{label}.npy\")\n",
    "    np.save(filename, core_area_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-blobs",
   "language": "python",
   "name": "conda-env-.conda-blobs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
